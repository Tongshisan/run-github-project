#!/usr/bin/env python3
"""
LLM æŸ¥è¯¢åˆ†æå™¨ - ä½¿ç”¨å¤§æ¨¡å‹ç†è§£è‡ªç„¶è¯­è¨€éœ€æ±‚
æ”¯æŒå¤šä¸ª LLM æä¾›å•†ï¼šOpenAIã€Anthropicã€DeepSeekã€Qwen ç­‰
"""

import os
import json
from typing import Dict, Optional
import requests


class LLMQueryAnalyzer:
    """ä½¿ç”¨ LLM åˆ†æç”¨æˆ·æŸ¥è¯¢"""
    
    # æ¨¡å‹é…ç½®
    MODELS = {
        'openai': {
            'api_url': 'https://api.openai.com/v1/chat/completions',
            'model': 'gpt-4o-mini',
            'api_type': 'openai'
        },
        'anthropic': {
            'api_url': 'https://api.anthropic.com/v1/messages',
            'model': 'claude-3-5-sonnet-20241022',
            'api_type': 'anthropic'
        },
        'deepseek': {
            'api_url': 'https://api.deepseek.com/v1/chat/completions',
            'model': 'deepseek-chat',
            'api_type': 'openai'  # DeepSeek å…¼å®¹ OpenAI API
        },
        'qwen': {
            'api_url': 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions',
            'model': 'qwen-turbo',
            'api_type': 'openai'  # é€šä¹‰åƒé—®å…¼å®¹ OpenAI API
        },
        'glm': {
            'api_url': 'https://open.bigmodel.cn/api/paas/v4/chat/completions',
            'model': 'glm-4-flash',
            'api_type': 'openai'  # æ™ºè°± GLM å…¼å®¹ OpenAI API
        }
    }
    
    def __init__(self, provider: str = "deepseek", api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– LLM åˆ†æå™¨
        
        Args:
            provider: LLM æä¾›å•† ("openai", "anthropic", "deepseek", "qwen", "glm")
            api_key: API å¯†é’¥
        """
        self.provider = provider.lower()
        
        if self.provider not in self.MODELS:
            available = ', '.join(self.MODELS.keys())
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}. å¯ç”¨: {available}")
        
        # è·å–é…ç½®
        config = self.MODELS[self.provider]
        self.api_url = config['api_url']
        self.model = config['model']
        self.api_type = config['api_type']
        
        # è·å– API key
        self.api_key = api_key or self._get_api_key()
        
        if not self.api_key:
            env_var = self._get_env_var_name()
            raise ValueError(f"è¯·è®¾ç½® {env_var} ç¯å¢ƒå˜é‡")
    
    def _get_api_key(self) -> Optional[str]:
        """æ ¹æ®æä¾›å•†è·å– API key"""
        env_vars = {
            'openai': 'OPENAI_API_KEY',
            'anthropic': 'ANTHROPIC_API_KEY',
            'deepseek': 'DEEPSEEK_API_KEY',
            'qwen': 'DASHSCOPE_API_KEY',  # é€šä¹‰åƒé—®
            'glm': 'GLM_API_KEY'  # æ™ºè°±
        }
        return os.getenv(env_vars.get(self.provider, f'{self.provider.upper()}_API_KEY'))
    
    def _get_env_var_name(self) -> str:
        """è·å–ç¯å¢ƒå˜é‡åç§°"""
        env_vars = {
            'openai': 'OPENAI_API_KEY',
            'anthropic': 'ANTHROPIC_API_KEY',
            'deepseek': 'DEEPSEEK_API_KEY',
            'qwen': 'DASHSCOPE_API_KEY',
            'glm': 'GLM_API_KEY'
        }
        return env_vars.get(self.provider, f'{self.provider.upper()}_API_KEY')
    
    def analyze_query(self, user_query: str) -> Dict[str, any]:
        """
        ä½¿ç”¨ LLM åˆ†æç”¨æˆ·æŸ¥è¯¢
        
        Args:
            user_query: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            
        Returns:
            åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å«å…³é”®è¯ã€æ•°é‡ã€è¯­è¨€ç­‰ä¿¡æ¯
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ª GitHub é¡¹ç›®æœç´¢åŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç”¨è‡ªç„¶è¯­è¨€æè¿°ä»–ä»¬æƒ³æ‰¾çš„é¡¹ç›®ï¼Œä½ éœ€è¦åˆ†æå¹¶æå–å…³é”®ä¿¡æ¯ã€‚

è¯·ä»¥ JSON æ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{
  "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],  // è‹±æ–‡å…³é”®è¯ï¼Œç”¨äº GitHub æœç´¢
  "count": 10,  // ç”¨æˆ·æƒ³è¦çš„ç»“æœæ•°é‡ï¼Œé»˜è®¤ 10
  "language": "python",  // ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚æœæŒ‡å®šï¼‰ï¼Œå¯é€‰å€¼: python, javascript, typescript, go, rust, java, ç­‰ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä¸º null
  "category": "library",  // é¡¹ç›®ç±»å‹: library, framework, tool, template, example, ç­‰
  "description": "CSS åŠ¨ç”»åº“"  // ç”¨ä¸€å¥è¯æè¿°ç”¨æˆ·æƒ³è¦ä»€ä¹ˆï¼ˆä¸­æ–‡ï¼‰
}

æ³¨æ„ï¼š
1. keywords å¿…é¡»æ˜¯è‹±æ–‡ï¼Œå› ä¸º GitHub ä¸»è¦æ˜¯è‹±æ–‡å†…å®¹
2. å¦‚æœç”¨æˆ·è¯´"æ‰¾ 10 ä¸ª"ï¼Œcount å°±æ˜¯ 10
3. language åªåœ¨ç”¨æˆ·æ˜ç¡®æŒ‡å®šç¼–ç¨‹è¯­è¨€æ—¶æ‰è®¾ç½®
4. å…³é”®è¯è¦å‡†ç¡®ï¼Œèƒ½æ‰¾åˆ°ç›¸å…³é¡¹ç›®"""

        user_prompt = f"ç”¨æˆ·éœ€æ±‚ï¼š{user_query}\n\nè¯·åˆ†æè¿™ä¸ªéœ€æ±‚å¹¶è¿”å› JSON æ ¼å¼çš„ç»“æœã€‚"
        
        try:
            if self.api_type == 'openai':
                # OpenAI å…¼å®¹çš„ API (OpenAI, DeepSeek, Qwen, GLM)
                result = self._call_openai_compatible(system_prompt, user_prompt)
            elif self.api_type == 'anthropic':
                # Anthropic Claude API
                result = self._call_anthropic(system_prompt, user_prompt)
            else:
                raise ValueError(f"æœªçŸ¥çš„ API ç±»å‹: {self.api_type}")
            
            # è§£æ JSON ç»“æœ
            analysis = json.loads(result)
            
            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
            if 'keywords' not in analysis:
                analysis['keywords'] = []
            if 'count' not in analysis:
                analysis['count'] = 10
            
            # ğŸ†• è¿‡æ»¤ç¦ç”¨å…³é”®è¯
            BANNED_KEYWORDS = {
                'graduation', 'university', 'study', 'practice', 
                'project', 'repository', 'website', 'example', 
                'sample', 'demo', 'tutorial', 'beginner',
                'interactive', 'awesome', 'cool', 'best', 'good',
                'learning', 'education'
            }
            analysis['keywords'] = [
                kw for kw in analysis['keywords']
                if kw.lower() not in BANNED_KEYWORDS
            ]
            
            # ğŸ†• é™åˆ¶å…³é”®è¯æ•°é‡ï¼ˆæœ€å¤š 2 ä¸ªï¼‰
            if len(analysis['keywords']) > 2:
                analysis['keywords'] = analysis['keywords'][:2]
            
            # é™åˆ¶æ•°é‡
            analysis['count'] = min(analysis['count'], 100)
            
            # æ·»åŠ æ’åºä¿¡æ¯
            analysis['sort'] = 'stars'
            analysis['order'] = 'desc'
            
            return analysis
            
        except Exception as e:
            print(f"âš ï¸  LLM åˆ†æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•è§„åˆ™åˆ†æ: {e}")
            # é™çº§åˆ°ç®€å•è§„åˆ™
            return self._fallback_analyze(user_query)
    
    def _call_openai_compatible(self, system_prompt: str, user_prompt: str) -> str:
        """
        è°ƒç”¨ OpenAI å…¼å®¹çš„ API
        é€‚ç”¨äº: OpenAI, DeepSeek, Qwen, GLM ç­‰
        """
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            'temperature': 0.3
        }
        
        # DeepSeek å’ŒæŸäº›æ¨¡å‹æ”¯æŒ response_format
        if self.provider in ['openai', 'deepseek']:
            data['response_format'] = {'type': 'json_object'}
        
        response = requests.post(self.api_url, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        return result['choices'][0]['message']['content']
    
    def _call_anthropic(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨ Anthropic Claude API"""
        headers = {
            'x-api-key': self.api_key,
            'anthropic-version': '2023-06-01',
            'content-type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'max_tokens': 1024,
            'system': system_prompt,
            'messages': [
                {'role': 'user', 'content': user_prompt}
            ],
            'temperature': 0.3
        }
        
        response = requests.post(self.api_url, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        content = result['content'][0]['text']
        
        # æå– JSONï¼ˆClaude å¯èƒ½ä¼šåŠ ä¸€äº›è¯´æ˜æ–‡å­—ï¼‰
        if '```json' in content:
            content = content.split('```json')[1].split('```')[0]
        elif '{' in content:
            start = content.index('{')
            end = content.rindex('}') + 1
            content = content[start:end]
        
        return content
    
    def _fallback_analyze(self, user_query: str) -> Dict[str, any]:
        """é™çº§åˆ°ç®€å•è§„åˆ™åˆ†æ"""
        query_lower = user_query.lower()
        
        # æå–æ•°é‡
        count = 10
        for word in user_query.split():
            if word.isdigit():
                count = int(word)
                break
        
        # æå–å…³é”®è¯ï¼ˆç®€å•å¤„ç†ï¼‰
        keywords = []
        exclude_words = {'æ‰¾', 'ä¸ª', 'çš„', 'åº“', 'é¡¹ç›®', 'ä»“åº“', 'ç›¸å…³', 'æœ€', 'å¥½', 'æ¨è', 'æ¨è'}
        for word in user_query.replace('ï¼Œ', ' ').replace(',', ' ').split():
            if word and word not in exclude_words and not word.isdigit():
                keywords.append(word)
        
        # æ£€æµ‹è¯­è¨€
        language = None
        language_map = {
            'python': ['python', 'py'],
            'javascript': ['javascript', 'js', 'node'],
            'typescript': ['typescript', 'ts'],
            'go': ['go', 'golang'],
            'rust': ['rust'],
            'java': ['java'],
        }
        
        for lang, lang_keys in language_map.items():
            if any(key in query_lower for key in lang_keys):
                language = lang
                break
        
        return {
            'keywords': keywords,
            'count': min(count, 100),
            'language': language,
            'sort': 'stars',
            'order': 'desc',
            'description': user_query
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•å¤šä¸ªæ¨¡å‹
    print("=" * 70)
    print("æµ‹è¯• LLM æŸ¥è¯¢åˆ†æå™¨")
    print("=" * 70)
    
    test_query = "æ‰¾ 10 ä¸ª CSS åŠ¨ç”»åº“"
    
    # å¯é€‰çš„æä¾›å•†
    providers = ['deepseek', 'openai', 'qwen', 'glm', 'anthropic']
    
    for provider in providers:
        try:
            print(f"\nå°è¯•ä½¿ç”¨ {provider.upper()}...")
            analyzer = LLMQueryAnalyzer(provider=provider)
            result = analyzer.analyze_query(test_query)
            
            print(f"âœ… {provider.upper()} æˆåŠŸ!")
            print(f"ç»“æœ: {json.dumps(result, ensure_ascii=False, indent=2)}")
            break  # æˆåŠŸä¸€ä¸ªå°±é€€å‡º
            
        except ValueError as e:
            print(f"âš ï¸  {provider.upper()}: {e}")
            continue
        except Exception as e:
            print(f"âŒ {provider.upper()} å¤±è´¥: {e}")
            continue
    else:
        print("\nâŒ æ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥äº†")
        print("\næç¤º: è¯·è‡³å°‘è®¾ç½®ä¸€ä¸ª API key:")
        print("  - export DEEPSEEK_API_KEY=sk-...")
        print("  - export OPENAI_API_KEY=sk-...")
        print("  - export DASHSCOPE_API_KEY=sk-...")  # é€šä¹‰åƒé—®
        print("  - export GLM_API_KEY=...")  # æ™ºè°±
        print("  - export ANTHROPIC_API_KEY=sk-ant-...")

